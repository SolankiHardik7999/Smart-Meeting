{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8571d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install YouTube_Transcript_Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248bac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72383a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9d776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "api_key = \"AIzaSyC63fOdRdvvxk7m4k4LGONElKinXIvh29s\"\n",
    "\n",
    "#1.query API \n",
    "\n",
    "rq = build(\"youtube\", \"v3\", developerKey=api_key).playlistItems().list(\n",
    "        part=\"contentDetails, snippet\",\n",
    "        playlistId=\"PLV1Xs08GmtwwXaJWhTcuMMwkGWbC_1fxH\",\n",
    "        maxResults=200,        \n",
    "        ).execute()\n",
    "        \n",
    "#2.Create a list with video Ids and Titles\n",
    "\n",
    "\n",
    "vid_ids = []\n",
    "vid_title = []\n",
    "pl_dict1 = dict()\n",
    "for item in rq[\"items\"]:\n",
    "    vid_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
    "    vid_title.append(item[\"snippet\"][\"title\"])\n",
    "for id in vid_ids:\n",
    "    try:\n",
    "        #3.Get transcripts\n",
    "        srt = YouTubeTranscriptApi.get_transcripts(id)\n",
    "        #4.For each video id extract the Key:\"text\" from a list of dictionaries \n",
    "\n",
    "        get_key_text = [\" \".join([a_dict[\"text\"] for a_dict in srt[0][i]]) for i in vid_ids]\n",
    "        #5.Create a dictionary with the title and transcript for each video id\n",
    "\n",
    "        \n",
    "        #pl_dict1.update(pl_dict)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pl_dict = dict(zip(vid_title,get_key_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fad5d352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategic Partnership 2022</td>\n",
       "      <td>[CLICK] DAVID SONTAG: So welcome\\nto spring 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Changes to Planning Rules - 29 August 2022</td>\n",
       "      <td>PETER SZOLOVITS:\\nAs David said, I've been at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finance &amp; Corporate Committee - Sep 15 2020</td>\n",
       "      <td>PETER SZOLOVITS: So\\nlast time we talked about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service Delivery - 17 May 2022</td>\n",
       "      <td>DAVID SONTAG: Today\\nwe'll be talking about ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finance &amp; Corporate Committee - Aug 18, 2020</td>\n",
       "      <td>[CLICK] [SQUEAK] [PAGES RUSTLING] [MOUSE DOUBL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iwi Consultative Committee Meeting - Sep 2, 2020</td>\n",
       "      <td>DAVID SONTAG: So I'll\\nbegin today's lecture b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Te Awamutu Community Board Zoom Meeting - Jun ...</td>\n",
       "      <td>PETER SZOLOVITS: OK. So today and next\\nTuesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Land Transport Strategy Workshop 2 March</td>\n",
       "      <td>PETER SZOLOVITS: All right. Let's get started....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Strategic Planning &amp; Policy Committee Meeting ...</td>\n",
       "      <td>PETER SZOLOVITS: Fortunately,\\nI have a guest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cambridge Community Board Meeting 2 March 2022</td>\n",
       "      <td>PROFESSOR: So welcome, everyone. Today is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cambridge Community Board Meeting 02 February ...</td>\n",
       "      <td>PETER SZOLOVITS: OK. Today's topic is\\ndiffere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Service Delivery Committee Workshop 15 Februar...</td>\n",
       "      <td>PROFESSOR: All right,\\neveryone, so we are ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Council meeting 19 May 2021</td>\n",
       "      <td>ADAM YALA: OK, great. Well, thank you for\\nthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Service Delivery Committee - Zoom Meeting</td>\n",
       "      <td>DAVID SONTAG: So today's lecture\\nis going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Private video</td>\n",
       "      <td>[SQUEAKING] [RUSTLING] [CLICKING] DAVID SONTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Audit &amp; Risk Committee - Zoom Meeting</td>\n",
       "      <td>PROFESSOR: Hi, everyone. We're getting started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cambridge Community Board Zoom Meeting</td>\n",
       "      <td>DAVID SONTAG: A\\nthree-part lecture today, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iwi Consultative Committee - Zoom Meeting</td>\n",
       "      <td>DAVID SONTAG: So we're done with\\nour segment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Strategic Planning &amp; Policy Committee - Zoom M...</td>\n",
       "      <td>PROFESSOR: So I'm going\\nto begin by trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Extraordinary Strategic Planning &amp; Policy Comm...</td>\n",
       "      <td>PETER SZOLOVITS: So\\ntoday's topic is workflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Extraordinary Strategic Planning &amp; Policy Comm...</td>\n",
       "      <td>PROFESSOR: All right. Let's get started. Welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Council - Zoom Meeting</td>\n",
       "      <td>PETER SZOLOVITS: OK,\\nso a little over a year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Waipa District Council - Extraordinary Regulat...</td>\n",
       "      <td>[SQUEAKING] [RUSTLING] [CLICKING] DAVID SONTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Copy: Finance &amp; Corporate Committee - Zoom Mee...</td>\n",
       "      <td>PROFESSOR: OK, so the\\nlast topic for the clas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                          Strategic Partnership 2022   \n",
       "1          Changes to Planning Rules - 29 August 2022   \n",
       "2         Finance & Corporate Committee - Sep 15 2020   \n",
       "3                      Service Delivery - 17 May 2022   \n",
       "4        Finance & Corporate Committee - Aug 18, 2020   \n",
       "5    Iwi Consultative Committee Meeting - Sep 2, 2020   \n",
       "6   Te Awamutu Community Board Zoom Meeting - Jun ...   \n",
       "7            Land Transport Strategy Workshop 2 March   \n",
       "8   Strategic Planning & Policy Committee Meeting ...   \n",
       "9      Cambridge Community Board Meeting 2 March 2022   \n",
       "10  Cambridge Community Board Meeting 02 February ...   \n",
       "11  Service Delivery Committee Workshop 15 Februar...   \n",
       "12                        Council meeting 19 May 2021   \n",
       "13          Service Delivery Committee - Zoom Meeting   \n",
       "14                                      Private video   \n",
       "15              Audit & Risk Committee - Zoom Meeting   \n",
       "16             Cambridge Community Board Zoom Meeting   \n",
       "17          Iwi Consultative Committee - Zoom Meeting   \n",
       "18  Strategic Planning & Policy Committee - Zoom M...   \n",
       "19  Extraordinary Strategic Planning & Policy Comm...   \n",
       "20  Extraordinary Strategic Planning & Policy Comm...   \n",
       "21                             Council - Zoom Meeting   \n",
       "22  Waipa District Council - Extraordinary Regulat...   \n",
       "23  Copy: Finance & Corporate Committee - Zoom Mee...   \n",
       "\n",
       "                                           Transcript  \n",
       "0   [CLICK] DAVID SONTAG: So welcome\\nto spring 20...  \n",
       "1   PETER SZOLOVITS:\\nAs David said, I've been at ...  \n",
       "2   PETER SZOLOVITS: So\\nlast time we talked about...  \n",
       "3   DAVID SONTAG: Today\\nwe'll be talking about ri...  \n",
       "4   [CLICK] [SQUEAK] [PAGES RUSTLING] [MOUSE DOUBL...  \n",
       "5   DAVID SONTAG: So I'll\\nbegin today's lecture b...  \n",
       "6   PETER SZOLOVITS: OK. So today and next\\nTuesda...  \n",
       "7   PETER SZOLOVITS: All right. Let's get started....  \n",
       "8   PETER SZOLOVITS: Fortunately,\\nI have a guest ...  \n",
       "9   PROFESSOR: So welcome, everyone. Today is the ...  \n",
       "10  PETER SZOLOVITS: OK. Today's topic is\\ndiffere...  \n",
       "11  PROFESSOR: All right,\\neveryone, so we are ver...  \n",
       "12  ADAM YALA: OK, great. Well, thank you for\\nthe...  \n",
       "13  DAVID SONTAG: So today's lecture\\nis going to ...  \n",
       "14  [SQUEAKING] [RUSTLING] [CLICKING] DAVID SONTAG...  \n",
       "15  PROFESSOR: Hi, everyone. We're getting started...  \n",
       "16  DAVID SONTAG: A\\nthree-part lecture today, and...  \n",
       "17  DAVID SONTAG: So we're done with\\nour segment ...  \n",
       "18  PROFESSOR: So I'm going\\nto begin by trying to...  \n",
       "19  PETER SZOLOVITS: So\\ntoday's topic is workflow...  \n",
       "20  PROFESSOR: All right. Let's get started. Welco...  \n",
       "21  PETER SZOLOVITS: OK,\\nso a little over a year ...  \n",
       "22  [SQUEAKING] [RUSTLING] [CLICKING] DAVID SONTAG...  \n",
       "23  PROFESSOR: OK, so the\\nlast topic for the clas...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(pl_dict,index=[0]).T\n",
    "data = dataset.reset_index()\n",
    "data.rename(columns = {'index':'Title',0:'Transcript'},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de5c144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f40d6ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DAVID SONTAG: So I'll\\nbegin today's lecture by giving a brief recap\\nof risk stratification. We didn't get to finish talking\\nsurvival modeling on Thursday, and so I'll go a little\\nbit more into that, and I'll answer some\\nof the questions that arose during our discussions\\nand on Piazza since. And then the vast majority\\nof today's lecture we'll be talking about a new topic-- in particular, physiological\\ntime series modeling. I'll give two examples of\\nphysiological time series modeling-- the first one\\ncoming from monitoring patients in intensive care units,\\nand the second one asking a very different\\ntype of question-- that of diagnosing patients'\\nheart conditions using EKGs. And both of these\\ncorrespond to readings that you had for\\ntoday's lecture, and we'll go into much\\nmore depth in these-- of those papers today, and\\nI'll provide much more color around them. So just to briefly remind you\\nwhere we were on Thursday, we talked about how one could\\nformalize risk stratification instead of as a classification\\nproblem of what would happen, let's say, in some\\npredefined time period, rather thinking about\\nrisk stratification as a regression question,\\nor regression task. Given what you know about\\na patient at time zero, predicting time to event-- so for example, here the\\nevent might be death, divorce, college graduation. And patient one-- that event\\nhappened at time step nine. Patient two, that event\\nhappened at time step 12. And for patient four, we don't\\nknow when that event happened, because it was censored. In particular, after\\ntime step seven, we no longer get to view\\nany of the patients' data, and so we don't know when\\nthat red dot would be-- sometime in the future or never. So this is what we mean by\\nright censor data, which is precisely what survival\\nmodeling is aiming to solve. Are there questions\\nabout this setup first? AUDIENCE: You flipped the x on-- DAVID SONTAG: Yeah,\\nI realized that. I flipped the x and the o\\nin today's presentation, but that's not relevant. So f of t is the\\nprobability of death, or the event occurring\\nat time step t. And although in this\\nslide I'm showing it as an unconditional\\nmodel, in general, you should think about this\\nas a conditional density. So you might be conditioning\\non some covariates or features that you have for that\\npatient at baseline. And very important\\nfor survival modeling and for the next\\nthings I'll tell you are the survival function,\\nto note it as capital S of t. And that's simply 1 minus the\\ncumulative density function. So it's the probability\\nthat the event occurring, which is time-- which is denoted\\nhere as capital T, occurs greater\\nthan some little t. So it's this function,\\nwhich is simply given to you by\\nthe integral from 0 to infinity of the density. So in pictures,\\nthis is the density. On the x-axis is time. The y-axis is the\\ndensity function. And this black curve is\\nwhat I'm denoting as f of t. And this white area is capital s\\nof c, the survival probability, or survival function. Yes? AUDIENCE: So I just\\nwant to be clear. So if you were to\\nintegrate the entire curve, [INAUDIBLE] by infinity you're\\ngoing to be [INAUDIBLE].. DAVID SONTAG: In the\\nway that I described it to here, yes, because we're\\ntalking about the time to event. But often we might be in\\nscenarios where the event may never occur, and so that-- you can formalize that in\\na couple of different ways. You could put that at point\\nmass at s of infinity, or you could simply say that\\nthe integral from 0 to infinity is some quantity less than 1. And in the readings\\nthat I'm referencing in the very bottom of\\nthose slides-- it shows you how you can very easily\\nmodify all of the frameworks I'm telling you about here\\nto deal with that scenario where the event may never occur. But for the purposes\\nof my presentation, you can assume that\\nthe event will always occur at some point. It's a very minor modification\\nwhere you, in essence, divide the densities by a constant,\\nwhich accounts for the fact that it wouldn't integrate\\nto one otherwise. Now, a key question\\nthat has to be solved when trying to use a parametric\\napproach to survivor modeling is, what should that\\nf of t look like? What should that density\\nfunction look like? And what I'm showing you here\\nis a table of some very commonly used density functions. What you see in\\nthese two columns-- on the right hand column is the\\ndensity function f of t itself. Lambda denotes some\\nparameter of the model. t is the time. And on this second middle\\ncolumn is the survival function. So this is obtained for these\\nparticular parametric forms by an analytical solution\\nsolving that integral from t to infinity. This is the analytic\\nsolution for that. And so these go by common\\nnames of exponential, weeble, log-normal, and so on. And critically, all of\\nthese have support only on the positive real numbers,\\nbecause the event can ever occur at negative time. Now, we live in a\\nday and age where we no longer have to make\\nstandard parametric assumptions for densities. We could, for example, try\\nto formalize the density as some output of some\\ndeep neural network. But if we don't use a\\nparametric approach, so there are two ways\\nto try to do that. One way to do that would\\nbe to say that we're going to model the post-- the distribution, f of t, as one\\nof these things, where lambda or whatever the\\nparameters of distribution are given to by the\\noutput of, let's say, a deep neural network\\non the covariate x. So that would be one approach. A very different\\napproach would be a non-parametric distribution\\nwhere you say, OK, I'm going to define f of\\nt extremely flexibly, not as one of these forms. And there one runs into a\\nslightly different challenge, because as I'll show\\nyou in the next slide, to do maximum\\nlikelihood estimation of these distributions\\nfrom censor data, one needs to get-- one needs\\nto make use of this survival function, s of t. And so if you're\\nf if t is complex, and you don't have a nice\\nanalytic solution for s of t, then you're going to\\nhave to somehow use a numerical approximation\\nof s of t during limiting. So it's definitely\\npossible, but it's going to be a little bit more effort. So now here's where I'm going\\nto get into maximum likelihood estimation of these\\ndistributions, and to define for you\\nthe likelihood function, I'm going to break it down\\ninto two different settings. The first setting\\nis an observation which is uncensored, meaning\\nwe do observe when the event-- death, for example-- occurs. And in that case, the\\nprobability of the event-- it's very simple. It's just probability of the\\nevent occurring at capital-- at capital T, random\\nvariable T, equals a little t-- is just f or t. Done. However, what happens\\nif, for this data point, you don't observe when the event\\noccurred because of censoring? Well, of course, you could just\\nthrow away that data point, not use it in your\\nestimation, but that's precisely what we mentioned\\nat the very beginning of last week's lecture-- was\\nthe goal of survival modeling to not do that,\\nbecause if we did that, it would introduce bias\\ninto our estimation procedure. So we would like to be able\\nto use that observation that this data\\npoint was censored, but the only information we\\ncan get from that observation is that capital\\nT, the event time, must have occurred\\nsome time larger than the observed-- the\\ntime of censoring, which is little t here. So we don't know precisely\\nwhen capital T was, but we know it's something larger than\\nthe observed centering time little of t. And that, remember, is precisely\\nwhat the survival function is capturing. So for a censored\\nobservation, we're going to use capital S of\\nt within the likelihood. So now we can then combine these\\ntwo for censored and uncensored data, and what we get is the\\nfollowing likelihood objective. This is-- I'm showing you here\\nthe log likelihood objective. Recall from last week that\\nlittle b of i simply denotes is this observation\\ncensored or not? So if bi is 1, it means\\nthe time that you're given is the time of the\\ncensoring event. And if bi is 0, it means\\nthe time you're given is the time that\\nthe event occurs. So here what we're going to do\\nis now sum over all of the data points in your data\\nset from little i equals 1 to little n of bi\\ntimes log of probability under the censored model\\nplus 1 minus bi times log of probability under\\nthe uncensored model. And so this bi is just going\\nto switch on which of these two you're going to use for\\nthat given data point. So the learning objective for\\nmaximum likelihood estimation here is very similar\\nto what you're used to in learning distributions\\nwith the big difference that, for censored\\ndata, we're going to use the survival function\\nto estimate its probability. Are there any questions? And this, of course,\\ncould then be optimized via your\\nfavorite algorithm, whether it be stochastic\\ngradient descent, or second order\\nmethod, and so on. Yep? AUDIENCE: I have a\\nquestion about the a kind of side project. You mentioned that we\\ncould use [INAUDIBLE].. DAVID SONTAG: Yes. AUDIENCE: And then combine it\\nwith the parametric approach. DAVID SONTAG: Yes. AUDIENCE: So is that\\ntrue that we just still have the parametric\\nassumption that we kind of map the input to the parameters? DAVID SONTAG: Exactly. That's exactly right. So consider the following\\npicture where for-- this is time, t. And this is f of t. You can imagine\\nfor any one patient you might have a\\ndifferent function. You might-- but they might all\\nbe of the same parametric form. So they might be\\nlike that, or maybe they're shifted a little bit. So you think about\\neach of these three things as being from the\\nsame parametric family of distributions, but\\nwith different means. And in this case,\\nthen the mean is given to as the output of\\nthe deep neural network. And so that would be the\\nway it would be used, and then one could just back\\npropagate in the usual way to do learning. Yep? AUDIENCE: Can you\\nrepeat what b sub i is? DAVID SONTAG: Excuse me? AUDIENCE: Could you\\nrepeat what b sub i is? DAVID SONTAG: b sub i is just an\\nindicator whether the i-th data point was censored\\nor not censored. Yes? AUDIENCE: So [INAUDIBLE] equal\\nit's more a probability density function [INAUDIBLE]. DAVID SONTAG: Cumulative\\ndensity function. AUDIENCE: Yeah, but\\n[INAUDIBLE] probability. No, for the [INAUDIBLE] it's\\nprobability density function. DAVID SONTAG Yes, so just to-- AUDIENCE: [INAUDIBLE] DAVID SONTAG: Excuse me? AUDIENCE: Will\\nthat be any problem to combine those\\ntwo types there? DAVID SONTAG: That's\\na very good question. So the observation was that\\nyou have two different types of probabilities used here. In this case, we're\\nusing something like the cumulative\\ndensity, whereas here we're using the probability\\ndensity function. The question was, are these\\ntwo on different scales? Does it make sense\\nto combine them in this type of linear fashion\\nwith the same weighting? And I think it does make sense. So think about a setting where\\nyou have a very small time range. You're not exactly sure\\nwhen this event occurs. It's something in\\nthis time range. In the setting of\\nthe censored data, where that time range could\\npotentially be very large, your model is providing-- your log probability\\nis somehow going to be much more flat,\\nbecause you're covering much more probability mass. And so that\\nobservation, I think, intuitively is likely\\nto have a much-- a bit of a smaller effect on\\nthe overall learning algorithm. These observations-- you know\\nprecisely where they are, and so as you deviate from that,\\nyou incur the corresponding log loss penalty. But I do think\\nthat it makes sense to have them in the same scale. If anyone in the room has done\\nwork with [INAUDIBLE] modeling and has a different answer\\nto that, I'd love to hear it. Not today, but maybe\\nsomeone in the future will answer this\\nquestion differently. I'm going to move on for now. So the remaining question that\\nI want to talk about today is how one evaluates\\nsurvival models. So we talked about binary\\nclassification a lot in the context of\\nrisk stratification in the beginning, and we talked\\nabout how area under the ROC curve is one measure of\\nclassification performance, but here we're doing more-- something more akin to\\nregression, not classification. A standard measure that's\\nused to measure performance is known as the C-statistic,\\nor concordance index. Those are one in the same-- and is defined as follows. And it has a very\\nintuitive definition. It sums over pairs\\nof data points that can be compared\\nto one another, and it says, OK, what\\nis the likelihood of the event happening\\nfor an event that occurs before an event-- another event. And what you want is that the\\nlikelihood of the event that, on average, in essence,\\nshould occur later should be larger than the event\\nthat should occur earlier. I'm going to first illustrate\\nit with this picture, and then I'll work\\nthrough the math. So here's the picture, and\\nthen we'll talk about the math. So what I'm showing you here\\nare every single observation in your data set,\\nand they're sorted by either the censoring\\ntime or the event time. So by black, I'm illustrating\\nuncensored data points. And by red, I'm denoting\\ncensored data points. Now, here we see that\\nthis data point-- the event happened before this\\ndata point's censoring event. Now, since this data\\npoint was censored, it means it's true event\\ntime you could think about as sometime into the far future. So what we would want\\nis that the model gives that the probability that\\nthis event happens by this time should be larger\\nthan the probability that this event\\nhappens by this time, because this actually\\noccurred first. And these two are comparable\\ntogether-- to each other. On the other hand, it\\nwouldn't make sense to compare y2 and y4,\\nbecause both of these were censored data\\npoints, and we don't know precisely when they occurred. So for example, it could\\nhave very well happened that the event 2\\nhappened after event 4. So what I'm showing you here\\nwith each of these lines are the pairwise\\ncomparisons that are actually possible to make. You can make pairwise\\ncomparisons, of course, between any pair of events\\nthat actually did occur, and you can make\\npairwise comparisons between censored events and\\nevents that occurred before it. Now, if you now look at this\\nformula, the formula in this indicate-- this is looking\\nat an indicator of survival functions between pairs of data\\npoints, and which pairs of data points? It was precisely those\\npairs of data points, which I'm showing comparisons\\nof with these blue lines here. So we're going to sum over i\\nsuch that bi is equal to 0, and remember that means it\\nis an uncensored data point. And then we look at-- we look at yi compared to\\nall other yj that's great-- that has a value greater than--\\nboth censored and uncensored. Now, if your data had no\\nsensor data points in it, then you can verify that,\\nin fact, this corresponds-- so there's one other\\nassumption one has to make, which is that-- suppose that your\\noutcome is binary. And so if you might wonder\\nhow you get a binary outcome from this, imagine that\\nyour density function looked a little bit like this,\\nwhere it could occur either at time 1 or time 2. So something like that. So if the event can\\noccur at only two times, not a whole range\\nof times, then this is analogous to\\na binary outcome. And so if you have\\na binary outcome like this and no censoring,\\nthen, in fact, that C-statistic is exactly equal to the\\narea under the ROC curve. So that just connects it a\\nlittle bit back to things we're used to. Yep? AUDIENCE: Just to make\\nsure that I understand. So y1 is going to be\\nwe observed an event, and y2 is going to be we\\nknow that no event occurred until that day? DAVID SONTAG: Every dot\\ncorresponds to one event, either censored or not. AUDIENCE: Thank you. DAVID SONTAG: And\\nthey're sorted. In this figure, they're\\nsorted by the time of either the censoring\\nor the event occurring. So I talked to-- when I talked about\\nC-statistic, it-- that's one way to measure\\nperformance of your survival modeling, but you\\nmight remember that I-- that when we talked about\\nbinary classification, we said how area\\nunder there ROC curve in itself is very\\nlimiting, and so we should think through\\nother performance metrics of relevance. So here are a few other\\nthings that you could do. One thing you could\\ndo is you could use the mean squared error. So again, thinking about\\nthis as a regression problem. But of course, that\\nonly makes sense for uncensored data points. So focus just in the\\nuncensored data points, look to see how well\\nwe're doing at predicting when the event occurs. The second thing one could\\ndo, since you have the ability to define the likelihood\\nof an observation, censored or not censored,\\none could hold out data, and look at the held-out\\nlikelihood or log likelihood of that held-out data. And the third thing\\nyou could do is you can-- after learning\\nusing this survival modeling framework, one could then turn\\nit into a binary classification problem by, for\\nexample, artificially choosing time ranges, like\\ngreater than three months is 1. Less than three months is 0. That would be one\\ncrude definition. And then once you've\\ndone a reduction to a binary\\nclassification problem, you could use all of\\nthe existing performance metrics they're used to thinking\\nabout for binary classification to evaluate the\\nperformance there-- things like positive\\npredictive value, for example. And you could, of course,\\nchoose different reductions and get different\\nperformance statistics out. So this is just a\\nsmall subset of ways to try to evaluate\\nsurvivor modeling, but it's a very,\\nvery rich literature. And again, on the\\nbottom of these slides, I pointed you to\\nseveral references that you could go\\nto to learn more. The final comment\\nI wanted to make is that I only told\\nyou about one estimator in today's lecture, and that's\\nknown as the likelihood based estimator. But there is a whole\\nother estimation approach for survival modelings, which\\nis very important to know about, that are called partial\\nlikelihood estimators. And for those of you who have\\nheard of Cox proportional hazards models-- and I\\nknow they were discussed in Friday's recitation-- that's an example\\nof a class of model that's commonly used within this\\npartial likelihood estimator. Now, at a very intuitive level,\\nwhat this partial likelihood estimator is doing is it's\\nworking with something like the C-statistic. So notice how the C-statistic\\nonly looks at relative orderings of events-- of their event occurrences. It doesn't care about exactly\\nwhen the event occurred or not. In some sense,\\nthere's a constant. There's-- in this\\nsurvival function, which could be divided out from\\nboth sides of this inequality, and it wouldn't affect\\nanything about the statistic. And so one could think\\nabout other ways of learning these models by\\nsaying, well, we want to learn a survival\\nfunction such that it gets the ordering\\ncorrect between data points. Now, such a survival function\\nwouldn't do a very good job. There's no reason it would\\ndo any good at getting the precise time of\\nwhen an event occurs, but if your goal were\\nto just figure out what is the sorted order\\nof patients by risk so that you're going to do an\\nintervention on the 10 most risky people, then getting that\\norder incorrect is going to be enough, and that's\\nprecisely the intuition used behind these partial\\nlikelihood estimators-- so they focus on something\\nwhich is a little bit less than the original\\ngoal, but in doing so, they can have much better\\nstatistical complexity, meaning the amount of\\ndata they need in order to fit this models well. And again, this is\\na very rich topic. All I wanted to do is\\ngive you a pointer to it so that you can go read more\\nabout it if this is something of interest to you. So now moving on\\ninto the recap, one of the most important points\\nthat we discussed last week was about non-stationarity. And there was a question\\nposted to Piazza, which was really interesting,\\nwhich is how do you actually deal with non-stationarity. And I spoke a lot\\nabout it existing, and I talked about\\nhow to test for it, but I didn't say what\\nto do if you have it. So I thought this was such\\nan interesting question that I would also talk about\\nit a bit during lecture. So the short answer is, if\\nyou have to have a solution that you deploy\\ntomorrow, then here's the hack that sometimes works. You take your most recent data,\\nlike the last three months' data, and you hope\\nthat there's not much non-stationarity\\nwithin last three months. You throw out all\\nthe historical data, and you just train using\\nthe most recent data. So a bit unsatisfying,\\nbecause you might have now extremely\\nlittle data left to learn with, but if you have enough volume,\\nit might be good enough. But the real\\ninteresting question from a research perspective\\nis how could you optimally use that historical data. So here are three\\ndifferent ways. So one way has to\\ndo with imputation. Imagine that the way in which\\nyour data was non-stationary was because there\\nwere, let's say, parts of time when certain\\nfeatures were just unavailable. I gave you this example last\\nweek of laboratory test results across time, and I showed\\nyou how there are sometimes these really big\\nblocks of time where no lab tests are available,\\nor very few are available. Well, luckily we live in a world\\nwith high dimensional data, and what that means is there's\\noften a lot of redundancy in the data. So what you could imagine\\ndoing is imputing features that you observed\\nto be missing, such that the missingness\\nproperties, in fact, aren't changing as much\\nacross time after imputation. And if you do that as\\na pre-processing step, it may allow you\\nto make use of much more of the historical data. A different approach, which\\nis intimately tied to that, has to do with\\ntransforming the data. Instead of imputing\\nit, transforming it into another representation\\naltogether, such that that presentation is\\ninvariant across time. And here I'm giving\\nyou a reference to this paper by Ganin et al\\nfrom the Journal of Machine Learning Research 2016,\\nwhich talks about how to do domain and variant\\nlearning of neural networks, and that's one\\napproach to do so. And I view those two as being\\nvery similar-- imputation and transformations. A second approach is\\nto re-weight the data to look like the current data. So imagine that you\\ngo back in time, and you say, you know what? I ICD-10 codes, for\\nsome very weird reason-- this is not true, by the way-- ICD-10 codes in\\nthis untrue world happen to be used between\\nMarch and April of 2003. And then they weren't\\nused again until 2015. So instead of throwing away\\nall of the previous data, we're going to\\nrecognize that those-- that three month\\ninterval 10 years ago was actually drawn from a very\\nsimilar distribution as what we're going to be\\ntesting on today. So we're going to weight those\\ndata points up very much, and down weight the\\ndata points that are less like the ones from today. That's the intuition behind\\nthese re-weighting approaches, and we're going to talk\\nmuch more about that in the context of\\ncausal inference, not because these two have\\nto do with each other, but they have-- they end up\\nusing a very similar technique for how to deal with datas\\nthat shift, or covariate shift. And the final technique\\nthat I'll mention is based on online\\nlearning algorithms. So the idea there is that there\\nmight be cut points, change points across time. So maybe the data looks one\\nway up until this change point, and then suddenly\\nthe data looks really different until\\nthis change point, and then suddenly\\nthe data looks very different on into the future. So here I'm showing you there\\nare two change points in which data set shift happens. What these online learning\\nalgorithms do is they say, OK, suppose we were\\nforced to make predictions throughout this\\ntime period using only the historical\\ndata to make predictions at each point in time. Well, if we could\\nsomehow recognize that there might\\nbe these shifts, we could design\\nalgorithms that are going to be robust to those shifts. And then one could try to\\nanalyze-- mathematically analyze those algorithms\\nbased on the amount of regret they would have to, for example,\\nan algorithm that knew exactly when those changes were. And of course, we don't\\nknow precisely when those changes were. And so there's a whole field of\\nalgorithms trying to do that, and here I'm just give me one\\ncitation for a recent work. So to conclude risk\\nstratification-- this is the last slide here. Maybe ask your\\nquestion after class. We've talked about\\ntwo approaches for formalizing risk\\nstratification-- first as binary classification. Second as regression. And in the regression\\nframework, one has to think about\\ncensoring, which is why we call it survival modeling. Second, in our examples,\\nand again in your homework assignment that's\\ncoming up next week, we'll see that\\noften the variables, the features that are most\\npredictive make a lot of sense. In the diabetes case, we said-- we saw how patients having\\ncomorbidities of diabetes, like hypertension, or\\npatients being obese were very predictive of\\npatients getting diabetes. So you might ask yourself, is\\nthere something causal there? Are those features that are very\\npredictive in fact causing-- what's causing the patient\\nto develop type 2 diabetes? Like, for example,\\nobesity causing diabetes. And this is where I\\nwant to caution you. You shouldn't interpret these\\nvery predictive features in a causal fashion,\\nparticularly not when one starts to work\\nwith high dimensional data, as we do in this course. The reason for that\\nis very subtle, and we'll talk about that in\\nthe causal inference lectures, but I just wanted to\\ngive you a pointer now that you shouldn't\\nthink about it in that way. And you'll understand\\nwhy in just a few weeks. And finally we talked about ways\\nof dealing with missing data. I gave you one\\nfeature representation for the diabetes case,\\nwhich was designed to deal with missing data. It said, was there any\\ndiagnosis code 250.01 in the last three months? And if there was, you have a 1. If you don't, 0. So it's designed to\\nrecognize that you don't have information, perhaps,\\nfor some large chunk of time in that window. But that missing data\\ncould also be dangerous if that missingness itself has\\ncaused you to non-stationarity, which is then going to result in\\nyour test distribution looking different from your\\ntraining distribution. And that's where approaches\\nthat are based on imputation could actually be very valuable,\\nnot because they improve your predictive accuracy\\nwhen everything goes right, but because they might improve\\nyour predictive accuracy when things go wrong. And so one of your readings\\nfor last week's lecture was actually an example of\\nthat, where they used a Gaussian process model to impute much of\\nthe missing data in a patient's continuous vital\\nsigns, and then they used a recurrent neural\\nnetwork to predict based on that imputed data. So in that case, there are\\nreally two things going on. First is this robustness\\nto data set shift, but there's a\\nsecond thing, which is going on as well,\\nwhich has to do with a trade-off between\\nthe amount of data you have and the complexity of\\nthe prediction problem. By doing imputations,\\nsometimes you make your problem\\nlook a bit simpler, and simpler algorithms might\\nsucceed where otherwise they would fail because not\\nhaving enough data. And that's something\\nthat you saw in that last week's reading. So I'm done with\\nrisk stratification. I'll take a one minute breather\\nfor everyone in the room, and then we'll start\\nwith the main topic of this lecture, which is\\nphysiological time-series modeling. Let's say started. So here's a baby that's\\nnot doing very well. This baby is in the\\nintensive care unit. Maybe it was a premature infant. Maybe it's a baby who\\nhas some chronic disease, and, of course, parents\\nare very worried. This baby is getting\\nvery close monitoring. It's connected to lots\\nof different probes. In number one here, it's\\nillustrating a three probe-- three lead ECG, which we'll be\\ntalking about much more, which is measuring its heart, how\\nthe baby's heart is doing. Over here, this number\\nthree is something attached to the baby's foot,\\nwhich is measuring its-- it's a pulse oximeter, which\\nis measuring the baby's oxygen saturation, the amount\\nof oxygen in the blood. Number four is a probe which\\nis measuring the baby's temperature and so on. And so we're really taking\\nreally close measurements of this baby, because\\nwe want to understand how is this baby doing. We recognize that there might\\nbe really sudden changes in the baby's state\\nof health that we want to be able to recognize\\nas early as possible. And so behind the scenes,\\nnext to this baby, you'll, of course, have a\\nhuge number of monitors, each of the monitors showing\\nthe readouts from each of these different signals. And this type of data is really\\nprevalent in intensive care units, but you'll also\\nsee in today's lecture how some aspects of\\nthis data are now starting to make its way\\nto the home, as well. So for example, EKGs are now\\navailable on Apple and Samsung watches to help understand-- help to help with\\ndiagnosis of arrhythmias, even for people at home. And so from this\\ntype of data, there are a number of really important\\nuse cases to think about. The first one is to\\nrecognize that often we're getting really noisy\\ndata, and we want to try to infer the true signal. So imagine, for example,\\nthe temperature probe. The baby's true\\ntemperature might be 98.5, but for whatever reason-- we'll\\nsee a few reasons here today-- maybe you're getting\\nan observation of 93. And you didn't know. Is that actually the\\ntrue baby temperature? In which case we-- it would be in a lot of trouble. Or is that an anomalous reading? So we like t be able to\\ndistinguish between those two things. And in other cases, we are\\ninterested in not necessarily fully understanding what's going\\non with the baby along each of those axes, but we\\njust want to use that data for predictive purposes,\\nfor risk stratification, for example. And so the type of\\nmachine learning approach that we'll take here will depend\\non the following three factors. First, do we have\\nlabel data available? For example, do we\\nknow the ground truth of what the baby's\\ntrue temperature was, at least for a few of the\\nbabies in the training set? Second. Do we have a good mechanistic\\nor statistical model of how this data might\\nevolve across time? We know a lot about\\nhearts, for example. Cardiology is one of\\nthose fields of medicine where it's really well studied. There are good\\nsimulators of hearts, and how they beat\\nacross time, and how that affects the electrical\\nstimulation across the body. And if we have these\\ngood mechanistic or statistical\\nmodels, that can often allow one to trade off not\\nhaving much label data, or just not having\\nmuch data period. And it's really\\nthese three points which I want to illustrate\\nthe extremes of in today's lecture-- what do you do when you\\ndon't have much data, and what you do\\nwhen-- what you can do when you have a ton of data. And I think it's going to\\nbe really informative for us as we go out into the world\\nand will have to tackle each of those two settings. So here's an example of two\\ndifferent babies with very different trajectories. One in the x-axis here\\nis time in seconds. The y-axis here-- I think seconds, maybe minutes. The y-axis here is beats per\\nminute of the baby's heart rate, and you see in\\nsome cases it's really fluctuating a lot up and down. In some cases, it's sort of\\ngoing in a similar-- in one direction, and in all cases,\\nthe short term observations are very different from the\\nlong range trajectories. So the first problem\\nthat I want us to think about is one\\nof trying to understand, how do we deconvolve between the\\ntruth of what's going on with, for example, the\\npatient's blood pressure or oxygen versus interventions\\nthat are happening to them? So on the bottom\\nhere, I'm showing examples of interventions. Here in this oxygen\\nuptake, we notice how between roughly 1,000\\nand 2,000 seconds suddenly there's no signal whatsoever. And that's an example of\\nwhat's called dropout. Over here, we see a\\ndifferent type of-- the effect of a\\ndifferent intervention, which is due to a\\nprobe recalibration. Now, at that time,\\nthere was a drop out followed by a sudden\\nchange in the values, and that's really happening\\ndue to a recalibration step. And in both of\\nthese cases, what's going on with the individual\\nmight be relatively constant across time,\\nbut what's being observed is dramatically affected\\nby those interventions. So we want to ask\\nthe question, can we identify those\\nartifactual processes? Can we identify that these\\ninterventions were happening at those points in time? And then, if we\\ncould identify them, then we could potentially\\nsubtract their effect out. So we could impute the\\ndata, which we know-- now know to be missing, and then\\nhave this much higher quality signal used for some\\ndownstream predictive purpose, for example. And the second reason why\\nthis can be really important is to tackle this problem\\ncalled alarm fatigue. Alarm fatigue is one of the\\nmost important challenges facing medicine today. As we get better and better\\nin doing risk stratification, as we come up with more and\\nmore diagnostic tools and tests, that means these red flags\\nare being raised more and more often. And each one of these has some\\nassociated false positive rate for it. And so the more tests you have-- suppose the false\\npositive rate is kept constant-- the more tests\\nyou have, the more likely it is that the union\\nof all of those is going to be some error. And so when you're in\\nan intensive care unit, there are alarms going\\noff all the time. And something that happens\\nis that nurses end up starting to ignore those\\nalarms, because so often those alarms are\\nfalse positives, are due to, for\\nexample, artifacts like what I'm showing you here. And so if we had techniques,\\nsuch as the ones we'll talk about right now,\\nwhich could recognize when, for example, the sudden drop\\nin a patient's heart rate is due to an artifact and not\\ndue to the patient's true heart rate dropping-- if we had enough\\nconfidence in that-- in distinguishing\\nthose two things, then we might not decide\\nto raise that red flag. And that might reduce the\\namount of false alarms, and that then might reduce\\nthe amount of alarm fatigue. And that could have a very\\nbig impact on health care. So the technique which\\nwe'll talk about today goes by the name of switching\\nlinear dynamical systems. Who here has seen\\na picture like this on-- this picture on\\nthe bottom before. About half of the room. So for the other\\nhalf of the room, I'm going to give\\na bit of a recap into probabilistic modeling. All of you are now familiar\\nwith general probabilities. So you're used to thinking\\nabout, for example, univariate Gaussian\\ndistributions. We talked about how one\\ncould model survival, which was an example of\\nsuch a distribution, but for today's\\nlecture, we're going to be thinking now about\\nmultivariate probability distributions. In particular, we'll be thinking\\nabout how a patient's state-- let's say their true\\nblood pressure-- evolves across time. And so now we're interested in\\nnot just the random variable at one point in time, but\\nthat same random variable at the second point in\\ntime, third point in time, fourth point in time, fifth\\npoint in time, and so on. So what I'm showing\\nyou here is known as a graphical model, also\\nknown as a Bayesian network. And it's one way of illustrating\\na multivariate probability distribution that has particular\\nconditional independence properties. Specifically, in\\nthis model, one node corresponds to one\\nrandom variable. So this is describing a\\njoint distribution on x1 through x6, y1 through y6. So it's this\\nmultivariate distribution on 12 random variables. The fact that this\\nis shaded in simply denotes that, at test time, when\\nwe use these models, typically these y variables are observed. Whereas our goal is usually\\nto infer the x variables. Those are typically unobserved,\\nmeaning that our typical task is one of doing posterior\\ninference to infer the x's given the y's. Now, associated with\\nthis graph, I already told you the nodes correspond\\nto random variables. The graph tells us how is this\\njoint distribution factorized. In particular, it's\\ngoing to be factorized in the following way-- as the product over\\nrandom variables of the probability of\\nthe i-th random variable. I'm going to use z to just\\ndenote a random variable. Think of z as the\\nunion of x and y. zi conditioned on the parents-- the values of the parents of zi. So I'm going to assume\\nthis factorization, and in particular for this\\ngraphical model, which goes by the name\\nof a Markov model, it has a very specific\\nfactorization. And we're just going to read\\nit off from this definition. So we're going to go in\\norder-- first x1, then y1, then x2, then y2,\\nand so on, which is going based on\\na root to children transversal of this graph. So the first random\\nvariable is x1. Second variable is y2, and\\nwhat are the parents of y-- sorry, what are\\nthe parents of y1. Everyone can say out loud. AUDIENCE: x1. DAVID SONTAG: x1. So y1 in this factorization\\nis only going to depend on x1. Next we have x2. What are the parents of x2? Everyone say out loud? AUDIENCE: x1. DAVID SONTAG: x1. Then we have y2. What are the parents of y2. Everyone say out loud. AUDIENCE: x2. DAVID SONTAG: x2 and so on. So this joint\\ndistribution is going to have a particularly\\nsimple form, which is given to by this\\nfactorization shown here. And this factorization\\ncorresponds one to one with the particular graph in\\nthe way that I just told you. And in this way, we can define\\na very complex probability distribution by a number of much\\nsimpler conditional probability distributions. For example, if each of the\\nrandom variables were binary, then to describe\\nprobability of y1 given x1, we only need two numbers. For each value of\\nx1, either 0 or 1, we give the probability\\nof y1 equals 1. And then, of course, probably y1\\nequals 0 is just 1 minus that. So we can describe that very\\ncomplicated joint distribution by a number of much\\nsmaller distributions. Now, the reason why I'm\\ndrawing it in this way is because we're making some\\nreally strong assumptions about the temporal\\ndynamics in this problem. In particular, the\\nfact that x3 only has an arrow from\\nx2 and not from x1 implies that x3 is\\nconditionally independent of x1. If you knew x2's value. So in some sense, think\\nabout this as cutting. If you're to take\\nx2 out of the model and remove all edges\\nincident on it, then x1 and x3 are now\\nseparated from one another. They're independent. Now, for those of you who\\ndo know graphical models, you'll recognize that that type\\nof independent statement that I made is only true\\nfor Markov models, and the semantics\\nfor Bayesian networks are a little bit different. But actually for this\\nmodel, it's-- they're one and the same. So we're going to make\\nthe following assumptions for the conditional\\ndistributions shown here. First, we're going to suppose\\nthat xt is given to you by a Gaussian distribution. Remember xt-- t is\\ndenoting a time step. Let's say 3-- it only\\ndepends in this picture-- the conditional\\ndistribution only depends on the previous\\ntime step's value, x2, or xt minus 1. So you'll notice how\\nI'm going to say here xt is going to\\ndistribute as something, but the only random\\nvariables in this something can be xt minus 1, according\\nto these assumptions. In particular, we're\\ngoing to assume that it's some Gaussian\\ndistribution, whose mean is some linear transformation\\nof xt minus 1, and which has a fixed\\ncovariance matrix q. So at each step of this process,\\nthe next random variable is some random walk from\\nthe previous random variable where you're moving according\\nto some Gaussian distribution. In a very similar\\nway, we're going to assume that yt is drawn also\\nas a Gaussian distribution, but now depending on xt. So I want you to think\\nabout xt as the true state of the patient. It's a vector that's\\nsummarizing their blood pressure, their\\noxygen saturation, a whole bunch of\\nother parameters, or maybe even just one of those. And y1 are the observations\\nthat you do observe. So let's say x1 is the\\npatient's true blood pressure. y1 is the observed\\nblood pressure, what comes from your monitor. So then a reasonable\\nassumption would be that, well, if\\nall this were equal, if it was a true\\nobservation, then y1 should be very close to x1. So you might assume that\\nthis covariance matrix is-- the covariance is-- the\\nvariance is very, very small. y1 should be very close to x1\\nif it's a good observation. And of course, if it's\\na noisy observation-- like, for example, if the probe\\nwas disconnected from the baby, then y1 should have\\nno relationship to x1. And that dependence on the\\nactual state of the world I'm denoting here by these\\nsuperscripts, s of t. I'm ignoring that right\\nnow, and I'll bring that in in the next slide. Similarly, the relationship\\nbetween x2 and x1 should be one which captures\\nsome of the dynamics that I showed in the previous\\nslides, where I showed over here now this is the patient's\\ntrue heart rate evolving across time, let's say. Notice how, if you\\nlook very locally, it looks like there are some\\nvery, very big local dynamics. Whereas if you\\nlook more globally, again, there's some smoothness,\\nbut there are some-- again, it looks like some random\\nchanges across time. And so those-- that\\ndrift has to somehow be summarized in this model\\nby that A random variable. And I'll get into more detail\\nabout that in just a moment. So what I just showed\\nyou was an example of a linear dynamical\\nsystem, but it was assuming that there were\\nnone of these events happening, none of these\\nartifacts happening. The actual model\\nthat we were going to want to be able\\nto use then is going to also\\nincorporate the fact that there might be artifacts. And to model that,\\nwe need to introduce additional random\\nvariables corresponding to whether those artifacts\\noccurred or not. And so that's now this model. So I'm going to let these S's-- these are other\\nrandom variables, which are denoting\\nartifactual events. They are also\\nevolving with time. For example, if there's\\nartifactual factual event at three seconds, maybe there's\\nalso an artifactual event at four seconds. And we like to model the\\nrelationship between those. That's why you\\nhave these arrows. And then the way that we\\ninterpret the observations that we do get depends\\non both the true value of what's going on\\nwith the patient and whether there was an\\nartifactual event or not. And you'll notice\\nthat there's also an edge going from\\nthe artifactual events to the true values\\nto note the fact that those interventions\\nmight actually be affecting the patient. For example, if you\\ngive them a medication to change their blood\\npressure, then that procedure is going to affect the next time\\nstep's value of the patient's blood pressure. So when one wants\\nto learn this model, you have to ask yourself,\\nwhat types of data do you have available? Unfortunately, it's very hard\\nto get data on both the ground truth, what's going\\non with the patient, and whether these artifacts\\ntruly occurred or not. Instead, what we actually have\\nare just these observations. We get these very noisy blood\\npressure draws across time. So what this paper does is\\nit uses a maximum likelihood estimation approach,\\nwhere it recognizes that we're going to be\\nlearning from missing data. We're going to explicitly\\nthink of these x's and the s's as latent variables. And we're going to\\nmaximize the likelihood of the whole entire model,\\nmarginalizing over x and s. So just maximizing the marginal\\nlikelihood over the y's. Now, for those of you who have\\nstudied unsupervised learning before, you might recognize\\nthat as a very hard learning problem. In fact, it's-- that\\nlikelihood is non-convex. And one could imagine all sorts\\nof a heuristics for learning, such as gradient descent,\\nor, as this paper uses, expectation maximization, and\\nbecause of that non-convexity, each of these\\nalgorithms typically will only reach a local\\nmaxima of the likelihood. So this paper uses EM,\\nwhich intuitively iterates between inferring those missing\\nvariables-- so imputing the x's and the s's given\\nthe current model, and doing posterior inference\\nto infer the missing variables given the\\nobserved variables, using the current model. And then, once you've\\nimputed those variables, attempting to refit the model. So that's called the\\nm-step for maximization, which updates the model and\\njust iterates between those two things. That's one learning\\nalgorithm which is guaranteed to reach a\\nlocal maxima of the likelihood under some regularity\\nassumptions. And so this paper\\nuses that algorithm, but you need to be\\nasking yourself, if all you ever\\nobserve are the y's, then will this algorithm\\never recover anything close to the true model? For example, there\\nmight be large amounts of non-identifiability here. It could be that you\\ncould swap the meaning of the s's, and you'd get a\\nsimilar likelihood on the y's. That's where bringing in domain\\nknowledge becomes critical. So this is going to be an\\nexample where we have no label data or very little label data. And we're going to do\\nunsupervised learning of this model, but\\nwe're going to use a ton of domain knowledge\\nin order to constrain the model as much as possible. So what is that\\ndomain knowledge? Well, first we're\\ngoing to use the fact that we know that a true heart\\nrate evolves in a fashion that can be very well modeled by\\nan autoregressive process. So the autoregressive process\\nthat's used in this paper is used to model the\\nnormal heart rate dynamics. In a moment, I'll tell you how\\nto model the abnormal heart rate observations. And intuitively-- I'll\\nfirst go over the intuition, then I'll give you the math. Intuitively what it\\ndoes is it recognizes that this complicated signal can\\nbe decomposed into two pieces. The first piece shown here\\nis called a baseline signal, and that, if you\\nsquint your eyes and you sort or ignore the\\nvery local fluctuations, this is what you get out. And then you can\\nlook at the residual of subtracting this signal,\\nsubtracting this baseline from the signal. And what you get\\nout looks like this. Notice here it's around 0 mean. So it's a 0 mean signal with\\nsome random fluctuations, and the fluctuations\\nare happening here at a much faster rate than-- and for the original baseline. And so the sum of bt and\\nthis residual is a very-- it looks-- is exactly equal\\nto the true heart rate. And each of these two things\\nwe can model very well. This we can model by\\na random walk with-- which goes very\\nslowly, and this we can model by a random walk\\nwhich goes very quickly. And that is exactly what I'm\\nnow going to show over here on the left hand side. bt, this baseline\\nsignal, we're going to model as a Gaussian\\ndistribution, which is parameterized as a function\\nof not just bt minus 1, but also bt minus\\n2, and bt minus 3. And so we're going to be\\ntaking a weighted average of the previous few time steps,\\nwhere we're smoothing out, in essence, the observation--\\nthe previous few observations. If you were to-- if you're being a\\nkeen observer, you'll notice that this is no\\nlonger a Markov model. For example, if this p1\\nand p2 are equal to 2, this then corresponds to a\\nsecond order Markov model, because each random variable\\ndepends on the previous two time steps of the Markov chain. And so after-- so you would\\nmodel now bt by this process, and you would\\nprobably be averaging over a large number\\nof previous time steps to get this smooth property. And then you'd model xt minus bt\\nby this autoregressive process, where you might,\\nfor example, just be looking at just the\\nprevious couple of time steps. And you recognize\\nthat you're just doing much more random fluctuations. And then-- so that's how one\\nwould now model normal heart rate dynamics. And again, it's just-- this is an example of\\na statistical model. There is no\\nmechanistic knowledge of hearts being\\nused here, but we can fit the data of normal\\nhearts pretty well using this. But the next question and\\nthe most interesting one is, how does one now\\nmodel artifactual events? So for that, that's where some\\nmechanistic knowledge comes in. So one models that\\nthe probe dropouts are given by recognizing\\nthat, if a probe is removed from the baby, then\\nthere should no longer be-- or at least if you-- after\\na small amount of time, there should no longer\\nbe any dependence on the true value of the baby. For example, the blood pressure,\\nonce the blood pressure probe is removed, is no longer\\nrelated to the baby's true blood pressure. But there might be some delay\\nto that lack of dependence. And so-- and that is going\\nto be encoded in some domain knowledge. So for example, in\\nthe temperature probe, when you remove the temperature\\nprobe from the baby, it starts heating up again--\\nor it starts cooling, so assuming that the ambient\\ntemperature is cooler than the baby's temperature. So you take it off the baby. It starts cooling down. How fast does it cool down? Well, you could assume\\nthat it cools down with some exponential decay\\nfrom the baby's temperature. And this is something\\nthat is very reasonable, and you could\\nimagine, maybe if you had label data for just\\na few of the babies, you could try to fit the\\nparameters of the exponential very quickly. And in this way, now, we\\nparameterize the conditional distribution of the temperature\\nprobe, given both the state and whether the artifact\\noccurred or not, using this very simple\\nexponential decay. And in this paper, they give\\na very similar type of-- they make similar types\\nof-- analogous types of assumptions for all of\\nthe other artifactual probes. You should think about\\nthis as constraining these conditional distributions\\nI showed you here. They're no longer allowed to\\nbe arbitrary distributions, and so that, when one does\\nnow expectation maximization to try to maximize the marginal\\nlikelihood of the data, you've now constrained\\nit in a way that you hopefully are\\nmoved on to identifyability of the learning problem. It makes all of the\\ndifference in learning here. So in this paper,\\ntheir evaluation did a little bit of fine\\ntuning for each baby. In particular, they assumed\\nthat the first 30 minutes near the start consists\\nof normal dynamics so that's there\\nare no artifacts. That's, of course,\\na big assumption, but they use that to try to\\nfine tune the dynamic model to fine tune it for each\\nbaby and for themselves. And then they looked\\nat the ability to try to identify\\nartifactual processes. Now, I want to go a little\\nbit slowly through this plot, because it's quite interesting. So what I'm showing\\nyou here is a ROC curve of the ability to\\npredict each of the four different types of artifacts. For example, at any\\none point in time, was there a blood sample\\nbeing taken or not? At any one point\\nin time, was there a core temperature disconnect\\nof the core temperature probe? And to evaluate it,\\nthey're assuming that they have some label data\\nfor evaluation purposes only. And of course, you want to be\\nat the very far top left corner up here. And what we're showing here\\nare three different curves-- the very faint\\ndotted line, which I'm going to trace out with\\nmy cursor, is the baseline. Think of that as a\\nmuch worse algorithm. Sorry. That's that line over there. Everyone see it? And this approach are\\nthe other two lines. Now, what's differentiating\\nthose other two lines corresponds to the particular\\ntype of approximate inference algorithm that's used. To do this posterior\\ninference, to infer the true value of the x's\\ngiven your noisy observations in the model given here is\\nactually a very hard inference problem. Mathematically, I\\nthink one can show that it's an NP-hard\\ncomputational problem. And so they have to\\napproximate it in some way, and they use two different\\napproximations here. The first approximation\\nis based on what they're calling a Gaussian\\nsum approximation, and it's a deterministic\\napproximation. The second approximation is\\nbased on a Monte Carlo method. And what you see here is that\\nthe Gaussian sum approximation is actually dramatically better. So for example, in\\nthis blood sample one, that the ROC curve looks like\\nthis for the Gaussian sum approximation. Whereas for the Monte\\nCarlo approximation, it's actually\\nsignificantly lower. And this is just to\\npoint out that, even in this setting, where\\nwe have very little data, we're using a lot of domain\\nknowledge, the actual details of how one does the\\nmath-- in particular, the proximate\\ninference-- can make a really big difference in the\\nperformance of this system. And so it's something\\nthat one should really think deeply about, as well. I'm going to skip that\\nslide, and then just mention very briefly this one. This is showing an\\ninference of the events. So here I'm showing you\\nthree different observations. And on the bottom here,\\nI'm showing the prediction of when artifact-- two different\\nartifactual events happened. And these predictions\\nwere actually quite good, using this model. So I'm done with that\\nfirst example, and-- and the-- just to recap\\nthe important points of that example, it was that\\nwe had almost no label data. We're tackling this problem\\nusing a cleverly chosen statistical model with some\\ndomain knowledge built in, and that can go really far. So now we'll shift gears to\\ntalk about a different type of problem involving\\nphysiological data, and that's of detecting\\natrial fibrillation. So what I'm showing you\\nhere is an AliveCore device. I own one of these. So if you want to drop\\nby my E25 545 office, you can-- you can\\nplay around with it. And if you attach it\\nto your mobile phone, it'll show you your electric\\nconductance through your heart as measured through\\nyour two fingers touching this device\\nshown over here. And from that, one can try to\\ndetect whether the patient has atrial fibrillation. So what is atrial fibrillation? Good question. It's [INAUDIBLE]. So this is from the\\nAmerican Heart Association. They defined atrial fibrillation\\nas a quivering or irregular heartbeat, also\\nknown as arrhythmia. And one of the big\\nchallenges is that it could lead to blood clot,\\nstroke, heart failure, and so on. So here is how a\\npatient might describe having atrial fibrillation. My heart flip-flops,\\nskips beats, feels like it's banging\\nagainst my chest wall, particularly when I'm\\ncarrying stuff up my stairs or bending down. Now let's try to look\\nat a picture of it. So this is a normal heartbeat. Hearts move-- pumping like this. And if you were to\\nlook at the signal output of the EKG of\\na normal heartbeat, it would look like this. And it's roughly corresponding\\nto the different-- the signal is corresponding\\nto different cycles of the heartbeat. Now for a patient who\\nhas atrial fibrillation, it looks more like this. So much more obviously abnormal,\\nat least in this figure. And if you look at the\\ncorresponding signal, it also looks very different. So this is just to give you\\nsome intuition about what I mean by atrial fibrillation. So what we're going to try\\nto do now is to detect it. So we're going to\\ntake data like that and try to classify it into a\\nnumber of different categories. Now this is something which\\nhas been studied for decades, and last year, 2017,\\nthere was a competition run by Professor Roger\\nMark, who is here at MIT, which is trying\\nto see, well, how could-- how good are we at\\ntrying to figure out which patients have different\\ntypes of heart rhythms based on data that\\nlooks like this? So this is a normal\\nrhythm, which is also called a sinus rhythm. And over here it's atrial-- this is an example one patient\\nwho has atrial fibrillation. This is another type of rhythm\\nthat's not atrial fibrillation, but is abnormal. And this is a noisy recording--\\nfor example, if a patient's-- doesn't really have their\\ntwo fingers very well put on to the two leads\\nof the device. So given one of these\\ncategories, can we predict-- one of these signals,\\ncould predict which category it came from? So if you looked at\\nthis, you might recognize that they look a bit different. So could some of\\nyou guess what might be predictive features\\nthat differentiate one of these signals\\nfrom the other? In the back? AUDIENCE: The\\npresence and absence of one of the peaks the QRS\\ncomplex are [INAUDIBLE].. DAVID SONTAG: So\\nspeak in English for people who don't know\\nwhat these terms mean. AUDIENCE: There is one\\nlarge piece, which can-- probably we can consider one\\nmV and there is another peak, which is sort of like-- they have reverse polarity\\nbetween normal rhythm and [INAUDIBLE]. DAVID SONTAG: Good. So are you a cardiologist? AUDIENCE: No. DAVID SONTAG: No, OK. So what the student\\nsuggested is one could look for sort\\nof these inversions to try to describe it a\\nlittle bit differently. So here you're suggesting\\nthe lack of those inversions is predictive of\\nan abnormal rhythm. What about another feature\\nthat could be predictive? Yep? AUDIENCE: The spacing\\nbetween the peaks is more irregular with the AF. DAVID SONTAG: The\\nspacing between beats is more irregular\\nwith the AF rhythm. So you're sort of\\nlooking at this. You see how here\\nthis spacing is very different from this spacing. Whereas in the normal\\nrhythm, sort of the spacing looks pretty darn regular. All right, good. So if I was to show you\\n40 examples of these and then ask you to\\nclassify some new ones, how well do you think\\nyou'll be able to do? Pretty well? I would be surprised if\\nyou couldn't do reasonably well at least distinguishing\\nbetween normal rhythm and AF rhythm, because there seem to be\\nsome pretty clear signals here. Of course, as you get\\ninto alternatives, then the story gets\\nmuch more complex. But let me dig in\\na little bit deeper into what I mean by this. So let's define\\nsome of these terms. Well, cardiologists have studied\\nthis for a really long time, and they have-- so\\nwhat I'm showing you here is one heart cycle. And they've-- you can put names\\nto each of the peaks that you would see in a regular heart\\ncycle-- so that-- for example, that very high peak is\\nknown as the R peak. And you could look at, for\\nexample, the interval-- so this is one beat. You could look at the interval\\nbetween the R peak of one beat and the R peak of\\nanother peak, and define that to be the RR interval. In a similar way,\\none could take-- one could find different\\ndistinctive elements of the signal-- by the way, each-- each time step\\ncorresponds to the heart being in a different position. For a healthy heart, these\\nare relatively deterministic. And so you could look at\\nother distances and derive features from those\\ndistances, as well, just like we were talking\\nabout, both within a beat and across beats. Yep? AUDIENCE: So what's\\nthe difference between a segment and\\nan interval again? DAVID SONTAG: I don't\\nknow what the difference between a segment\\nand an interval is. Does anyone else know? I mean, I guess the\\ninterval is between probably the heads of peaks, whereas\\nsegments might refer to within a interval. That's my guess. Does someone know better? For the purpose\\nof today's class, that's a good enough\\nunderstanding. The point is this\\nis well understood. One could derive\\nfeatures from this. AUDIENCE: By us. DAVID SONTAG: By us. So what would a traditional\\napproach be to this problem? So this is-- I'm pulling this figure\\nfrom a paper from 2002. What it'll do is it'll\\ntake in that signal. It'll do some filtering of it. Then it'll run a peak\\ndetection logic, which will find these\\npeaks, and then it'll measure intervals between\\nthese peaks and within a beat. And it'll take\\nthose computations or make some\\ndecision based on it. So that's a\\ntraditional algorithm, and they work pretty reasonably. And so what do I mean\\nby signal processing? Well, this is an\\nexample of that. I encourage any of you to go\\nhome today and try to code up a peaked finding algorithm. It's not that hard, at\\nleast not to get an OK one. You might imagine\\nkeeping a running tab of what's the highest\\nsignal you've seen so far. Then you look to see what\\nis the first time it drops, and the second time-- and the\\nnext time it goes up larger than, let's say, the previous-- suppose that one of-- you want to look for when the\\ndrop is-- the maximum value-- recent maximum\\nvalue divided by 2. And then you-- then you reset. And you can imagine in this\\nway very quickly coding up a peak finding algorithm. And so this is just,\\nagain, to give you some intuition behind what a\\ntraditional approach would be. And then you can very\\nquickly see that that-- once you start to look at\\nsome intervals between peaks, that alone is often good\\nenough for predicting whether a patient has\\natrial fibrillation. So this is a figure\\ntaken from paper in 2001 showing a single\\npatient's time series. So the x-axis is for\\nthat single patient, their heart beats across time. The y-axis is just\\nshowing the RR interval between the previous beat\\nand the current beat. And down here in the\\nbottom is the ground truth of whether the patient\\nis assessed to have-- to be in-- to have a normal\\nrhythm or atrial fibrillation, which is noted as this\\nhigher value here. So these are AF rhythms. This is normal. This is AF again. And what you can see is that\\nthe RR interval actually gets you pretty far. You notice how it's\\npretty high up here. Suddenly it drops. The RR interval\\ndrops for a while, and that's when\\nthe patient has AF. Then it goes up again. Then it drops again, and so on. And so it's not deterministic,\\nthe relationship, but there's definitely a lot\\nof signal just from that. So you might say,\\nOK, well, what's the next thing we could do\\nto try to clean up the signal a little bit more? So flash backwards from 2001 to\\n1970 here at MIT, studied by-- actually, no, this is not MIT. This is somewhere else, sorry. But still 1970-- where they\\nused a Markov model very similar to the Markov models\\nwe were just talking about in the previous example to model\\nwhat a sequence of normal RR intervals looks like versus\\nwhat a sequence of abnormal, for example, AF RR\\nintervals looks like. And in that way,\\none can recognize that, for any one\\nobservation of an RR interval might not by itself be\\nperfectly predictive, but if you look at sort\\nof a sequence of them for a patient with\\natrial fibrillation, there is some common\\npattern to it. And you can-- one can detect it\\nby just looking at likelihood of that sequence under each\\nof these two different models, normal and abnormal. And that did pretty well--\\neven better than the previous approaches for-- for predicting\\natrial fibrillation. This is the paper I\\nwanted to say from MIT. Now 1991, this is also\\nfrom Roger Mark's group. Now this is a neural network\\nbased approach, where it says, OK, we're going to take\\na bunch of these things. We're going to derive a\\nbunch of these intervals, and then we're going to throw\\nthat through a black box supervised machine\\nlearning algorithm to predict whether a\\npatient has AF or not. So these are very-- first of all, there are\\nsome simple approaches here that work reasonably well. Using neural networks in this\\ndomain is not a new thing, but where are we as a field? So as I mentioned, there was\\nthis competition last year, and what I'm showing\\nyou here-- the citation is from one of the\\nwinning approaches. And this winning approach\\nreally brings the two paradigms together. It extracts a large number\\nof expert derived features-- so shown here. And these are exactly\\nthe types of things you might think, like\\nproportion, median RR interval of regular rhythms,\\nmax RR irregularity measure. And there's just a whole\\nrange of different things that you can imagine manually\\nderiving from the data. And you throw all\\nof these features into a machine\\nlearning algorithm, maybe a random forest, maybe a\\nneural network, doesn't matter. And what you get out is a\\nslightly better algorithm than what if you\\nhad just come up with a simple rule on your own. That was the winning\\nalgorithm then. And in the summary paper, they\\nconjectured that, well, maybe it's the case that they were-- they'd expected that\\nconvolutional neural networks would win. And they were surprised that\\nnone of the winning solutions involved convolution\\nneural networks. And they conjectured that may be\\nthe reason why is because maybe with these 8,000 patients\\nthat they had [INAUDIBLE] that just wasn't enough to give the\\nmore complex models advantage. So flip forward now to\\nthis year and the article that you read in your\\nreadings in Nature Medicine, where the Stanford\\ngroup now showed how a convolutional neural\\nnetwork approach, which is, in many ways, extremely\\nnaive-- all it does is it takes the\\nsequence data in. It makes no attempt at trying\\nto understand the underlying physiology, and just\\npredicts from that-- can do really, really well. And so there are\\ncouple of differences that I want to emphasize\\nto the previous work. First, the censor is different. Whereas the previous work\\nused this alive core censor, in this paper from\\nStanford, they're using a different censor\\ncalled the Zio patch, which is attached to the human\\nbody and conceivably much less noisy. So that's one big difference. The second big difference\\nis that there's dramatically more data. Instead of 8,000\\npatients to train from, now they have over\\n90,000 records from 50,000 different\\npatients to train from. The third major\\ndifference is that now, rather than just trying to\\nclassify into four categories-- normal, abnormal,\\nother, or noisy-- now we're going\\nto try to classify into 14 different categories. We're, in essence, breaking\\napart that other class into much finer grain\\ndetail of different types of abnormal rhythms. And so here are some of\\nthose other abnormal rhythms, things like complete\\nheart block, and a bunch of other\\nnames I can't pronounce. And from each one of these,\\nthey gathered a lot of data. And that actually did-- so it's not described\\nin the paper, but I've talked to\\nthe authors, and they did-- they gathered this data\\nin a very interesting way. So they sort of-- they did\\ntheir training iteratively. They looked to see\\nwhere their errors were, and then they went and gathered\\nmore data from patients with that subcategory. So many of these\\nother categories are very under-- might\\nbe underrepresented in the general population,\\nbut they actually gather a lot of\\npatients of that type in their data set for\\ntraining purposes. And so I think those\\nthree things ended up making a very big difference. So what is their\\nconvolutional network? Well, first of all,\\nit's a 1-D signal. So it's a little bit\\ndifferent from the con nets you typically see\\nin computer vision, and I'll show you an\\nillustration of that in the next slide. It's a very deep model. So it's 34 layers. So the input comes in on the\\nvery top in this picture. It's passed through\\na number of layers. Each layer consists of\\nconvolution followed by rectified linear\\nunits, and there is sub sampling at every\\nother layer so that you go from a very wide signal-- so a very long-- I can't remember how long-- 1 second long signal\\nsummarized down into sort of much-- just many\\nsmaller number of dimensions, which you then have a sort\\nof fully connected layer at the bottom to do\\nfor your predictions. And then they also have\\nthese shortcut connections, which allow you to pass\\ninformation from earlier layers down to the very\\nend of the network, or even into\\nintermediate layers. And for those of you who\\nare familiar with residual networks, it's the same idea. So what is a 1D convolution? Well, it looks a\\nlittle bit like this. So this is the signal. I'm going to just approximate\\nit by a bunch of 1's and 0's. I'll say this is a 1. This is a 0. This is a 1, 1, so on. A convolutional network has\\na filter associated with it. That filter is then\\napplied in a 1D model. It's applied in\\na linear fashion. It's just taken a dot product\\nwith the filter's values, with the values of the\\nsignal at each point in time. So it looks a little\\nbit like this, and this is what you get out. So this is the convolution\\nof a single filter with the whole signal. And the computation I did\\nthere-- so for example, this first number came\\nfrom taking the dot product of the first three numbers-- 1, 0, 1-- with the filter. So it's 1 times 2 plus 3 times\\n0 plus 1 times 1, which is 3. And so each of the\\nsubsequent numbers was computed in the same way. And I usually have you figure\\nout what this last one is, but I'll leave that\\nfor you to do at home. And that's what a\\n1D convolution is. And so they have-- they do this\\nfor lots of different filters. Each of those filters might\\nbe of varying lengths, and each of those will\\ndetect different types of signal patterns. And in this way, after\\nhaving many layers of these, one can, in an\\nautomatic fashion, extract many of the same types\\nof signals used in that earlier work, but also be much\\nmore flexible to detect some new ones, as well. Hold your question,\\nbecause I need to wrap up. So in the paper\\nthat you read, they talked about how\\nthey evaluated this. And so I'm not going to go\\ninto much depth in it now. I just want to point out\\ntwo different metrics that they used. So the first metric\\nthey used was what they called a\\nsequential error metric. What that looked at is you\\nhad this very long sequence for each patient, and\\nthey labeled different one second intervals\\nof that sequence into abnormal,\\nnormal, and so on. So you could ask,\\nhow good are we at labeling each of\\nthe different points along the sequence? And that's the sequence metric. The different-- the second\\nmetric is the set metric, and that looks at,\\nif the patient has something that's abnormal\\nanywhere, did you detect it? So that's, in essence,\\ntaking an or of each of those 1\\nsecond intervals, and then looking\\nacross patients. And from a clinical\\ndiagnostic perspective, the set metric might be\\nmost useful, but then when you want to\\nintrospect and understand where is that happening,\\nthen the sequential metric is important. And the key take home message\\nfrom the paper is that, if you compared the model's\\npredictions-- this is, I think, using an f1 metric-- to what you would get from\\na panel of cardiologists, these models are doing as well,\\nif not better than these panels of cardiologists. So this is extremely exciting. This is technology--\\nor variance of this is technology that you're\\ngoing to see deployed now. So for those of you who have\\npurchased these Apple watches, these Samsung watches, I don't\\nknow exactly what they're using, but I\\nwouldn't be surprised if they're using\\ntechniques similar to this. And you're going to see much\\nmore of that in the future. So this is going to be\\nreally the first example in this course so\\nfar of something that's really been deployed. And so in summary,\\nwe're very often in the realm of not enough data. And in this lecture today,\\nwe gave two examples how you can deal with that. First, you can try to use\\nmechanistic and statistical models to try to work\\nin settings where you don't have much data. And in other extremes,\\nyou do have a lot of data, and you can try to\\nignore that, and just use these black box approaches. That's all for today.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Transcript'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7dc74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\hardi\\anaconda3\\Projects\\Capstone Project\\CSV_Files\\Strategic_planning_Meeting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4b65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
