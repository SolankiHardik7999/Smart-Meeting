{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f63ffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d3ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hardi\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d319a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from sumy) (3.7)\n",
      "Collecting docopt<0.7,>=0.6.1\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting pycountry>=18.2.23\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from sumy) (2.27.1)\n",
      "Collecting breadability>=0.1.20\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "Requirement already satisfied: chardet in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from pycountry>=18.2.23->sumy) (61.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.4)\n",
      "Building wheels for collected packages: breadability, docopt, pycountry\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21712 sha256=794920fd40f9e9b169cc1b9749236524fd04c3b54cc8abe0b4b0ee3bd8091e14\n",
      "  Stored in directory: c:\\users\\hardi\\appdata\\local\\pip\\cache\\wheels\\ba\\9f\\70\\7795228568b81b57a8932755938da9fb1f291b0576752604aa\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=137fa5f52452b6d54fc56db59b7065a933237cfc06076df8e90f0e878856cbf3\n",
      "  Stored in directory: c:\\users\\hardi\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "  Building wheel for pycountry (PEP 517): started\n",
      "  Building wheel for pycountry (PEP 517): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681895 sha256=bdc86ec392c8d97fb6ef02adbeefcca4ca4ede2a0c2854caa9d02679ec9797f4\n",
      "  Stored in directory: c:\\users\\hardi\\appdata\\local\\pip\\cache\\wheels\\47\\15\\92\\e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
      "Successfully built breadability docopt pycountry\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04062f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da2011",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7128a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd9ef63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = 'Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children.They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways.They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f807a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pre-processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31227d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Transcript_Without_Stopword</th>\n",
       "      <th>Transcript_Lemmantized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1. Introduction and Scope</td>\n",
       "      <td>patrick winston: welcome to 6034. i don't know...</td>\n",
       "      <td>patrick winston: welcome 6034. know deal micro...</td>\n",
       "      <td>patrick winston: welcome 6034. know deal micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2. Reasoning: Goal Trees and Problem Solving</td>\n",
       "      <td>what we're going to talk about today, is goals...</td>\n",
       "      <td>we're going talk today, goals. way little warm...</td>\n",
       "      <td>we're going talk today, goals. way little warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3. Reasoning: Goal Trees and Rule-Based Expert...</td>\n",
       "      <td>professor patrick winston: ladies and gentleme...</td>\n",
       "      <td>professor patrick winston: ladies gentlemen, e...</td>\n",
       "      <td>professor patrick winston: lady gentlemen, eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4. Search: Depth-First, Hill Climbing, Beam</td>\n",
       "      <td>patrick winston: today we're going to be talki...</td>\n",
       "      <td>patrick winston: today we're going talking sea...</td>\n",
       "      <td>patrick winston: today we're going talking sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5. Search: Optimal, Branch and Bound, A*</td>\n",
       "      <td>professor: it was written about route 66, whic...</td>\n",
       "      <td>professor: written route 66, used main highway...</td>\n",
       "      <td>professor: written route 66, used main highway...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                          1. Introduction and Scope   \n",
       "1           1       2. Reasoning: Goal Trees and Problem Solving   \n",
       "2           2  3. Reasoning: Goal Trees and Rule-Based Expert...   \n",
       "3           3        4. Search: Depth-First, Hill Climbing, Beam   \n",
       "4           4           5. Search: Optimal, Branch and Bound, A*   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  patrick winston: welcome to 6034. i don't know...   \n",
       "1  what we're going to talk about today, is goals...   \n",
       "2  professor patrick winston: ladies and gentleme...   \n",
       "3  patrick winston: today we're going to be talki...   \n",
       "4  professor: it was written about route 66, whic...   \n",
       "\n",
       "                         Transcript_Without_Stopword  \\\n",
       "0  patrick winston: welcome 6034. know deal micro...   \n",
       "1  we're going talk today, goals. way little warm...   \n",
       "2  professor patrick winston: ladies gentlemen, e...   \n",
       "3  patrick winston: today we're going talking sea...   \n",
       "4  professor: written route 66, used main highway...   \n",
       "\n",
       "                              Transcript_Lemmantized  \n",
       "0  patrick winston: welcome 6034. know deal micro...  \n",
       "1  we're going talk today, goals. way little warm...  \n",
       "2  professor patrick winston: lady gentlemen, eng...  \n",
       "3  patrick winston: today we're going talking sea...  \n",
       "4  professor: written route 66, used main highway...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9019eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d315bc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Transcript_Without_Stopword</th>\n",
       "      <th>Transcript_Lemmantized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Introduction and Scope</td>\n",
       "      <td>patrick winston: welcome to 6034. i don't know...</td>\n",
       "      <td>patrick winston: welcome 6034. know deal micro...</td>\n",
       "      <td>patrick winston: welcome 6034. know deal micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Reasoning: Goal Trees and Problem Solving</td>\n",
       "      <td>what we're going to talk about today, is goals...</td>\n",
       "      <td>we're going talk today, goals. way little warm...</td>\n",
       "      <td>we're going talk today, goals. way little warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Reasoning: Goal Trees and Rule-Based Expert...</td>\n",
       "      <td>professor patrick winston: ladies and gentleme...</td>\n",
       "      <td>professor patrick winston: ladies gentlemen, e...</td>\n",
       "      <td>professor patrick winston: lady gentlemen, eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Search: Depth-First, Hill Climbing, Beam</td>\n",
       "      <td>patrick winston: today we're going to be talki...</td>\n",
       "      <td>patrick winston: today we're going talking sea...</td>\n",
       "      <td>patrick winston: today we're going talking sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Search: Optimal, Branch and Bound, A*</td>\n",
       "      <td>professor: it was written about route 66, whic...</td>\n",
       "      <td>professor: written route 66, used main highway...</td>\n",
       "      <td>professor: written route 66, used main highway...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                          1. Introduction and Scope   \n",
       "1       2. Reasoning: Goal Trees and Problem Solving   \n",
       "2  3. Reasoning: Goal Trees and Rule-Based Expert...   \n",
       "3        4. Search: Depth-First, Hill Climbing, Beam   \n",
       "4           5. Search: Optimal, Branch and Bound, A*   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  patrick winston: welcome to 6034. i don't know...   \n",
       "1  what we're going to talk about today, is goals...   \n",
       "2  professor patrick winston: ladies and gentleme...   \n",
       "3  patrick winston: today we're going to be talki...   \n",
       "4  professor: it was written about route 66, whic...   \n",
       "\n",
       "                         Transcript_Without_Stopword  \\\n",
       "0  patrick winston: welcome 6034. know deal micro...   \n",
       "1  we're going talk today, goals. way little warm...   \n",
       "2  professor patrick winston: ladies gentlemen, e...   \n",
       "3  patrick winston: today we're going talking sea...   \n",
       "4  professor: written route 66, used main highway...   \n",
       "\n",
       "                              Transcript_Lemmantized  \n",
       "0  patrick winston: welcome 6034. know deal micro...  \n",
       "1  we're going talk today, goals. way little warm...  \n",
       "2  professor patrick winston: lady gentlemen, eng...  \n",
       "3  patrick winston: today we're going talking sea...  \n",
       "4  professor: written route 66, used main highway...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e19f1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# Apply the vectorizer to the corpus\n",
    "X = vectorizer.fit_transform(data['Transcript_Lemmantized'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c955ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LSA on the TF-IDF matrix\n",
    "lsa = TruncatedSVD(n_components=2)\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "# Print the top words for each topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e0585db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "\tthat: 0.28\n",
      "\tgoing: 0.24\n",
      "\tone: 0.20\n",
      "\twe: 0.18\n",
      "\tre: 0.16\n",
      "Topic 1:\n",
      "\tequal: 0.29\n",
      "\tminus: 0.21\n",
      "\tsub: 0.17\n",
      "\tplus: 0.13\n",
      "\tintegral: 0.12\n",
      "patrick winston: welcome 6034 know deal microphone we'll see happens going good year we've got [inaudible] bunch interesting people always interesting see people named child two decade ago find overwhelmed emilys many peters, pauls, marys, enough call forth suitable song point lot jesses genders [inaudible] genders duncan, where's duncan? are, duncan changed hairstyle want assure use thane cawdor taking course semester i'm going tell artificial intelligence today, subject about there's 10% percent turnover roster last 24 hours expect another 10% turnover next 24 hours, too know many sightseers, wanting know something want do i'm going tell we're going semester, know get here i'm going walk outline i'm going start talking artificial intelligence is, it i'll give little bit history artificial intelligence, conclude covenant run course one laptops, please i'll explain covenant end it? well, must something thinking let's start here, definition artificial intelligence, saying thinking, whatever is definition artificial intelligence rather broad we're going say thinking also perception, action philosophy class, i'd stop right say, subject we're going talk problem involving thinking, perception, action philosophy clas\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    print(f\"Topic {i}:\")\n",
    "    terms_in_topic = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_in_topic, key=lambda x: x[1], reverse=True)[:5]\n",
    "    for term, weight in sorted_terms:\n",
    "        print(f\"\\t{term}: {weight:.2f}\")\n",
    "    \n",
    "# Generate a summary\n",
    "summary = []\n",
    "for doc_idx in range(X_lsa.shape[0]):\n",
    "    top_topic = X_lsa[doc_idx].argmax()\n",
    "    top_sentence = sorted(enumerate(data['Transcript_Lemmantized'][0][doc_idx].split('.')), key=lambda x: X_lsa[doc_idx, top_topic], reverse=True)[0][1]\n",
    "    summary.append(top_sentence)\n",
    "print(''.join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb60bddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34890"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Transcript'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8f68e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=PlaintextParser.from_string(data['Transcript_Lemmantized'][0],Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ba2a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philosophy class, i'd stop right say, subject we're going talk problem involving thinking, perception, action.\n",
      "even humanity class, mit approach make model use explain past, predict future, understand subject, control world.\n",
      "that's whey algebra high school, algebraic notation expose constraint make possible actually figure many customer get number advertisement place newspaper.\n",
      "one ever took stuff seriously, except fun [inaudible] project level thing work matching programs, on.\n",
      "b c 3. late dawn age, began turn attention purely symbolic reasoning thinking little bit perceptual apparatus.\n",
      "go through, example, atlanta airport, airplane parked rule-based expert system know park aircraft effectively.\n",
      "age begin realize definition actually little incomplete, much intelligence thinking, perception, action acting separately, loop tie together.\n",
      "perspective ai person like me, chomsky seems saying is, learned begin describe things, way intimately connected language.\n",
      "information little suspect two reasons, one asked people self report many lecture thought attended.\n",
      "know many celebrating religious holiday friday, putting lot resource online get review another way.\n"
     ]
    }
   ],
   "source": [
    "lsa_summarizer=LsaSummarizer()\n",
    "lsa_summary= lsa_summarizer(parser.document,10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in lsa_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bd2c4",
   "metadata": {},
   "source": [
    "##### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "533afd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def calculate_jaccard(word_tokens1, word_tokens2):\n",
    "\t# Combine both tokens to find union.\n",
    "\tboth_tokens = word_tokens1 + word_tokens2\n",
    "\tunion = set(both_tokens)\n",
    "\n",
    "\t# Calculate intersection.\n",
    "\tintersection = set()\n",
    "\tfor w in word_tokens1:\n",
    "\t\tif w in word_tokens2:\n",
    "\t\t\tintersection.add(w)\n",
    "\n",
    "\tjaccard_score = len(intersection)/len(union)\n",
    "\treturn jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9d131f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in c:\\users\\hardi\\anaconda3\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb927fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.972972972972973,\n",
       "   'p': 0.11145510835913312,\n",
       "   'f': 0.1999999981557099},\n",
       "  'rouge-2': {'r': 0.875, 'p': 0.05255631033249911, 'f': 0.09915682861058386},\n",
       "  'rouge-l': {'r': 0.972972972972973,\n",
       "   'p': 0.11145510835913312,\n",
       "   'f': 0.1999999981557099}}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "r = Rouge()\n",
    "r.get_scores(data['Transcript_Lemmantized'][0],str(lsa_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a2dbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6577f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbb0e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lsa_summarizer, 'lsa.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e98645",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lsa_summarizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lsa_summarizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e9523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
